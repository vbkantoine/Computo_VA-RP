{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# current root\n",
    "base_dir = r'/Users/antoinevanbiesbroeck/Documents/GitHub/Nils/Computo_VA-RP'\n",
    "sys.path.append(base_dir)\n",
    "import os\n",
    "\n",
    "py_dir = os.path.join(base_dir, \"python_files\")\n",
    "if py_dir not in sys.path:\n",
    "    sys.path.append(py_dir)\n",
    "#print(sys.path)\n",
    "from aux_optimizers import *\n",
    "from stat_models_torch import *\n",
    "from neural_nets import *\n",
    "from variational_approx import *\n",
    "from div_metrics_torch import *\n",
    "from constraints import *\n",
    "\n",
    "import scipy.special as spc\n",
    "from scipy.stats import gaussian_kde\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from matplotlib import gridspec\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "path_plot = os.path.join(base_dir, \"plots_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On non constrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. recover the VARP\n",
    "p = 50   \n",
    "q = 2      \n",
    "N = 50     \n",
    "J = 500   \n",
    "T = 50     \n",
    "input_size = p  \n",
    "output_size = q\n",
    "low = 0.0001        \n",
    "upp = 1 + low\n",
    "mu_a, sigma2_a = 0, 1\n",
    "#mu_a, sigma2_a = 8.7 * 10**-3, 1.03\n",
    "Probit = torch_ProbitModel(use_log_normal=True, mu_a=mu_a, sigma2_a=sigma2_a, set_beta=None, alt_scaling=True)\n",
    "n_samples_prior = 10**6\n",
    "alpha = 0.5\n",
    "name_file = 'Probit_results_unconstrained_torch_state'\n",
    "file_path = os.path.join(path_plot, name_file)\n",
    "\n",
    "seed_all(0)\n",
    "sqrt2 = np.sqrt(2)\n",
    "act_bet = lambda x: torch.log(1- 0.5*(1+torch.erf(x/sqrt2)) )\n",
    "NN = NetProbitSeparate(input_size, m1=0, s1=0.1, b1=0, pre_act=[nn.Identity(), act_bet], act1=[torch.exp, torch.exp])\n",
    "# NN = DifferentActivations(NN, [torch.exp, nn.Softplus()])\n",
    "# NN = AffineTransformation(NN, low, upp)\n",
    "NN.load_state_dict(torch.load(file_path, weights_only=True))\n",
    "VA = VA_NeuralNet(neural_net=NN, model=Probit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. load a data file and compute posteriors\n",
    "\n",
    "n_samples_post = 5000\n",
    "T_mcmc = 5*10**4 + 1 \n",
    "sigma2_0 = torch.tensor(1.)\n",
    "eps_0 = torch.randn(p)\n",
    "\n",
    "def aposteriori_VARP(numb_file) :\n",
    "    file_path = os.path.join(base_dir, r'SUR_alpha_impact/run_AJ/model_noSUR_J_{}'.format(numb_file))\n",
    "\n",
    "    file = pickle.load(open(file_path, 'rb'))\n",
    "    data_A = file['A']\n",
    "    data_Z = file['Z']\n",
    "    \n",
    "    theta_logs = {}\n",
    "\n",
    "    for N in np.arange(1,26)*10 :\n",
    "\n",
    "        seed_all(0)\n",
    "        Xstack = np.stack((data_Z[:N],data_A[:N]),axis=1)\n",
    "        X = torch.tensor(Xstack)\n",
    "        D = X.unsqueeze(1)\n",
    "        Probit.data = D\n",
    "        #eps_0 = 10 * torch.ones(p)\n",
    "        eps_MH, batch_acc = VA.MH_posterior(eps_0, T_mcmc, sigma2_0, target_accept=0.4, adap=True, Cov=True, disable_tqdm=False)\n",
    "        theta_MH = NN(eps_MH)\n",
    "        with torch.no_grad():\n",
    "            theta_MH = theta_MH.detach().numpy()\n",
    "        theta_post_nocstr = theta_MH[-n_samples_post:,-n_samples_post:]\n",
    "\n",
    "        theta_logs[N] = theta_post_nocstr\n",
    "\n",
    "    pickle.dump({'logs':{'post': theta_logs}, 'A':data_A, 'S':data_Z }, open(os.path.join(base_dir, r'SUR_alpha_impact/run_AJ/model_noSUR_VARP_{}'.format(numb_file)), 'wb') )\n",
    "\n",
    "files_numb = [3,30,31,32,33,34,35,36,37,38]\n",
    "\n",
    "def all_aposterioriVARP() :\n",
    "    for i in files_numb:\n",
    "        aposteriori_VARP(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. output an example of estimate\n",
    "from bayes_frag import config\n",
    "from bayes_frag.data import Data\n",
    "from bayes_frag.reference_curves import Reference_saved_MLE\n",
    "\n",
    "data = Data('PGA', csv_path='Res_ASG_SA_PGA_RL_RNL_80000.csv', quantile_C=0.9, name_inte='rot_nlin', shuffle=True)\n",
    "ref = Reference_saved_MLE(data, os.path.join(config.data_path, 'ref_MLE_ASG_80000_{}'.format('PGA')))\n",
    "num_clust = 25\n",
    "ref._compute_empirical_curves(num_clust) \n",
    "ref._compute_MC_data_tab()\n",
    "\n",
    "numb_file= 3\n",
    "N = 50\n",
    "\n",
    "file_VARP = os.path.join(base_dir, r'SUR_alpha_impact/run_AJ/model_noSUR_VARP_{}'.format(numb_file))\n",
    "file_J = os.path.join(base_dir, r'SUR_alpha_impact/run_AJ/model_noSUR_J_{}'.format(numb_file))\n",
    "\n",
    "\n",
    "def compute_frags_cred(theta) :\n",
    "    curves = 1/2 + 1/2*spc.erf( (np.log(data.a_tab)[None] - np.log(theta[:,None,0]))/theta[:,None,1] )\n",
    "    q1 = np.quantile(curves, 1-0.05/2, axis=0)\n",
    "    q2 = np.quantile(curves, 0.05/2, axis=0)\n",
    "    return q1,q2\n",
    "\n",
    "model_J = pickle.load(open(file_J, 'rb'))\n",
    "model_VARP = pickle.load(open(file_VARP, 'rb'))\n",
    "\n",
    "fig = plt.figure(figsize=(4,3))\n",
    "ax = fig.add_subplot()\n",
    "q1,q2 = compute_frags_cred(model_J['post']['logs'][50])\n",
    "ax.fill_between(data.a_tab, q1, q2, color='blue', alpha=0.4)\n",
    "ax.plot(data.a_tab, q1, color='blue', alpha=0.4, label='AJ')\n",
    "\n",
    "q1,q2 = compute_frags_cred(model_VARP['post']['logs'][50])\n",
    "ax.fill_between(data.a_tab, q1, q2, color='blue', alpha=0.4)\n",
    "ax.plot(data.a_tab, q1, color='red', alpha=0.4, label='VARP')\n",
    "\n",
    "ax.plot(ref.a_tab_MC, ref.curve_MC, color='darkcyan', alpha=0.6, label='ref')\n",
    "ax.plot(ref.a_tab_MC, ref.curve_MC-ref.curve_MC_var, '--', color='darkcyan', alpha=0.6)\n",
    "ax.plot(ref.a_tab_MC, ref.curve_MC+ref.curve_MC_var, '--', color='darkcyan', alpha=0.6)\n",
    "\n",
    "ax.plot(model_J['A'], model_J['S'], 'x', marwidth=1, color='red', label='obs')\n",
    "\n",
    "ax.legend()\n",
    "ax.set_ylim(-0.01, 1.01)\n",
    "ax.set_xlabel(r'$a$ = PGA (m/s$^2$)')\n",
    "ax.set_ylabel(r'$P_f(a)$')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On contrained prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. recover the VARP\n",
    "kappa = 0.15\n",
    "# K_val = np.mean((theta_sample_prior[:,1]**kappa)**(1/alpha))\n",
    "# c_val = np.mean((theta_sample_prior[:,1]**kappa)**(1+1/alpha))\n",
    "constr_val = 0.839594841003418\n",
    "# alpha_constr = np.mean((theta_sample_prior[:,0]**-kappa + 1)**-1)\n",
    "# print(f'Constraint value estimation : {K_val/c_val}')  # = 0.839594841003418 \n",
    "\n",
    "# Parameters and classes\n",
    "p = 50     # latent space dimension\n",
    "q = 2      # parameter space dimension\n",
    "N = 50    # number of data samples\n",
    "J = 500    # nb samples for MC estimation in MI\n",
    "T = 50     # nb samples MC marginal likelihood\n",
    "alpha = 0.5\n",
    "input_size = p  \n",
    "output_size = q\n",
    "low = 0.0001          # lower bound \n",
    "upp = 1 + low\n",
    "n_samples_prior = 10**6\n",
    "\n",
    "mu_a, sigma2_a = 0, 1\n",
    "#mu_a, sigma2_a = 8.7 * 10**-3, 1.03\n",
    "Probit = torch_ProbitModel(use_log_normal=True, mu_a=mu_a, sigma2_a=sigma2_a, set_beta=None, alt_scaling=True)\n",
    "\n",
    "# Constraints\n",
    "beta = torch.tensor([kappa])\n",
    "b = torch.tensor([[1,constr_val]]) \n",
    "T_cstr = 100000\n",
    "eta_augm = torch.tensor([[0.,1.]])\n",
    "eta = torch.tensor([[0.,1.]])\n",
    "name_file = 'Probit_results_constrained_torch_state'\n",
    "file_path = os.path.join(path_plot, name_file)\n",
    "\n",
    "seed_all(0)\n",
    "sqrt2 = np.sqrt(2)\n",
    "act_bet = lambda x: torch.log(1- 0.5*(1+torch.erf(x/sqrt2)) )\n",
    "NN = NetProbitSeparate(input_size, m1=0, s1=0.1, b1=0, pre_act=[nn.Identity(), act_bet], act1=[torch.exp, torch.exp])\n",
    "# NN = SingleLinear(input_size, output_size, m1=0, s1=0.1, b1=0, act1=nn.Identity())\n",
    "# NN = DifferentActivations(NN, [torch.exp, nn.Softplus()])\n",
    "# NN = AffineTransformation(NN, low, upp)\n",
    "NN.load_state_dict(torch.load(file_path, weights_only=True))\n",
    "VA = VA_NeuralNet(neural_net=NN, model=Probit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. load a data file and compute posteriors\n",
    "\n",
    "n_samples_post = 5000\n",
    "T_mcmc = 5*10**4 + 1 \n",
    "sigma2_0 = torch.tensor(1.)\n",
    "eps_0 = torch.randn(p)\n",
    "\n",
    "def aposteriori_VARP_constrained(numb_file) :\n",
    "    file_path = os.path.join(base_dir, r'SUR_alpha_impact/run_AJ/model_noSUR_J_adapt_{}'.format(numb_file))\n",
    "\n",
    "    file = pickle.load(open(file_path, 'rb'))\n",
    "    data_A = file['A']\n",
    "    data_Z = file['Z']\n",
    "    \n",
    "    theta_logs = {}\n",
    "\n",
    "    for N in np.arange(1,26)*10 :\n",
    "\n",
    "        seed_all(0)\n",
    "        Xstack = np.stack((data_Z[:N],data_A[:N]),axis=1)\n",
    "        X = torch.tensor(Xstack)\n",
    "        D = X.unsqueeze(1)\n",
    "        Probit.data = D\n",
    "        #eps_0 = 10 * torch.ones(p)\n",
    "        eps_MH, batch_acc = VA.MH_posterior(eps_0, T_mcmc, sigma2_0, target_accept=0.4, adap=True, Cov=True, disable_tqdm=False)\n",
    "        theta_MH = NN(eps_MH)\n",
    "        with torch.no_grad():\n",
    "            theta_MH = theta_MH.detach().numpy()\n",
    "        theta_post_nocstr = theta_MH[-n_samples_post:,-n_samples_post:]\n",
    "\n",
    "        theta_logs[N] = theta_post_nocstr\n",
    "\n",
    "    pickle.dump({'logs':{'post': theta_logs}, 'A':data_A, 'S':data_Z }, open(os.path.join(base_dir, r'SUR_alpha_impact/run_AJ/model_noSUR_VARP_adapt_{}'.format(numb_file)), 'wb') )\n",
    "\n",
    "files_numb = [3,30,31,32,33,34,35,36,37,38]\n",
    "\n",
    "def all_aposterioriVARP_constrained() :\n",
    "    for i in files_numb:\n",
    "        aposteriori_VARP_constrained(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. output an example of estimate\n",
    "from bayes_frag import config\n",
    "from bayes_frag.data import Data\n",
    "from bayes_frag.reference_curves import Reference_saved_MLE\n",
    "\n",
    "data = Data('PGA', csv_path='Res_ASG_SA_PGA_RL_RNL_80000.csv', quantile_C=0.9, name_inte='rot_nlin', shuffle=True)\n",
    "ref = Reference_saved_MLE(data, os.path.join(config.data_path, 'ref_MLE_ASG_80000_{}'.format('PGA')))\n",
    "num_clust = 25\n",
    "ref._compute_empirical_curves(num_clust) \n",
    "ref._compute_MC_data_tab()\n",
    "\n",
    "numb_file= 3\n",
    "N = 50\n",
    "\n",
    "file_VARP = os.path.join(base_dir, r'SUR_alpha_impact/run_AJ/model_noSUR_VARP_adapt_{}'.format(numb_file))\n",
    "file_J = os.path.join(base_dir, r'SUR_alpha_impact/run_AJ/model_noSUR_J_adapt_{}'.format(numb_file))\n",
    "\n",
    "\n",
    "def compute_frags_cred(theta) :\n",
    "    curves = 1/2 + 1/2*spc.erf( (np.log(data.a_tab)[None] - np.log(theta[:,None,0]))/theta[:,None,1] )\n",
    "    q1 = np.quantile(curves, 1-0.05/2, axis=0)\n",
    "    q2 = np.quantile(curves, 0.05/2, axis=0)\n",
    "    return q1,q2\n",
    "\n",
    "model_J = pickle.load(open(file_J, 'rb'))\n",
    "model_VARP = pickle.load(open(file_VARP, 'rb'))\n",
    "\n",
    "fig = plt.figure(figsize=(4,3))\n",
    "ax = fig.add_subplot()\n",
    "q1,q2 = compute_frags_cred(model_J['post']['logs'][50])\n",
    "ax.fill_between(data.a_tab, q1, q2, color='blue', alpha=0.4)\n",
    "ax.plot(data.a_tab, q1, color='blue', alpha=0.4, label='constr AJ')\n",
    "\n",
    "q1,q2 = compute_frags_cred(model_VARP['post']['logs'][50])\n",
    "ax.fill_between(data.a_tab, q1, q2, color='blue', alpha=0.4)\n",
    "ax.plot(data.a_tab, q1, color='red', alpha=0.4, label='constr VARP')\n",
    "\n",
    "ax.plot(ref.a_tab_MC, ref.curve_MC, color='grey', alpha=0.6, label='ref')\n",
    "ax.plot(ref.a_tab_MC, ref.curve_MC-ref.curve_MC_var, '--', color='grey', alpha=0.6)\n",
    "ax.plot(ref.a_tab_MC, ref.curve_MC+ref.curve_MC_var, '--', color='grey', alpha=0.6)\n",
    "\n",
    "ax.plot(model_J['A'], model_J['S'], 'x', marwidth=1, color='darkcyan', label='obs')\n",
    "\n",
    "ax.legend()\n",
    "ax.set_ylim(-0.01, 1.01)\n",
    "ax.set_xlabel(r'$a$ = PGA (m/s$^2$)')\n",
    "ax.set_ylabel(r'$P_f(a)$')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
